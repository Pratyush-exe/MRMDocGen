{
    "overview": "The Credit Line Decrease (CLD) model is used to identify high risks accounts with\nthe objective to mitigate potential losses by decreasing their credit limit. The\nmodel will be used on all the RRB credit card customers.\nRRB branded credit card is a core product of RRB and accounts for ~$90 million\nANR with ~20 million open accounts till Dec\u201922.\nThe model has been built using Dec 2018 development vintage. February 2018\nand April 2019 has been used for out-of-time (OOT) validations. The model has\nbeen built on entire card customers except for the customers whose past 12\nmonths historical data is not known.\nThe model estimates the likelihood of an account having a status of 60+ days\npast due at the end of 18 months (classified as \u2018bad\u2019 hereafter in this document).",
    "data_prep": "The model has been developed using the extracts from the Card Master File\n(CMF). Given that the development of the model was priority based for the\nbusiness based on the impact analysis of quick model developed earlier, a\nlimited set of features were used from a previous model (APD model). This was\ndone to facilitate quick development and implementation to suit business needs.\nGiven that the APD model uses attributes from varied behavior dimensions, all\nthe dimensions were captured for this model as well. The model also uses on-us\ndata along with the bureau data. This data was used to create trended derived\nvariables and was used in model development. Daily on-us variables and daily\nbureau trigger were also used to capture daily variations in the customer\ncharacteristics.",
    "model_name": "XGBoost:v1.0.0",
    "model_methadology": "XGBoost and Logistic Regression are two techniques used for creating the model\nalong with GBM trees. The final model is built using XGBoost and this is\ndetermined based on the performance benefits observed in using XGBoost. It is\nobserved that XGBoost outperforms both the other models on all the important\nbusiness metrics and does so consistently across a wide range of data points.\nExtreme Gradient Boosting Machines (XGBoost) has been used for model\ndevelopment. XGBoost is a widely used technique for both Classification and\nRegression outcomes. It is a stage-wise additive modelling technique, which\nimproves upon predictions by building decision trees on residuals remaining at\nany stage. For a classification outcome, XGBoost is built based on a Bernoulli\ndistribution and optimizes for a log loss function. The residuals in a classification\nproblem are defined by gradients of the log loss function. At each stage,\nXGBoost uses decision trees to predict the remaining residuals. An extensive\nhyper-parameter tuning was performed in a Grid search pattern to obtain the\noptimal set of parameters.",
    "assumptions": "The model uses XGBoost to predict the probability of an account being in 3+\nbucket at the end of 18 months. ",
    "conclusion": "As per the MRM policy requirement, model should be reviewed annually to\nensure the model usage for the next year. This year model was due for\nrevalidation, hence re-validation is performed and submitted at place of Annual\nModel Review (AMR). An AMR will be submitted for the model in the next annual\nvalidation exercise to be held in October this year on the latest available\nperformance results during the validation.\nThe performance checks would include metrics like PSI, KS, ROB, MAPE etc. and\nall MRM required metrics for AMR."

}